import streamlit as st
from llama_index import StorageContext, load_index_from_storage
from llama_index.llms import OpenAI
from llama_index.query_engine import RetrieverQueryEngine
from llama_index.retrievers import VectorIndexRetriever

INDEX_DIR = "index"

st.set_page_config(
    page_title="Wertgarantie Chatbot", layout="wide"
)

st.markdown("""
    <h1 style='text-align: center;'>ğŸ¤– Wertgarantie æ™ºèƒ½åŠ©æ‰‹</h1>
    <p style='text-align: center;'>åŸ¹è®­äº Wertgarantie å®˜æ–¹ FAQï¼Œæ”¯æŒç”¨æˆ·é—®é¢˜ç­”å¤</p>
""", unsafe_allow_html=True)

# åŠ è½½å‘é‡ç´¢å¼•
@st.cache_resource(show_spinner=True)
def load_index():
    llm = OpenAI(model="gpt-4o")
    storage_context = StorageContext.from_defaults(persist_dir=INDEX_DIR)
    index = load_index_from_storage(storage_context)
    return index

index = load_index()
retriever = VectorIndexRetriever(index=index, similarity_top_k=5)
query_engine = RetrieverQueryEngine(retriever=retriever)

# ç”¨æˆ·è¾“å…¥
user_input = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜...")

if user_input:
    st.chat_message("user").markdown(user_input)
    with st.spinner("AI å›å¤ä¸­..."):
        response = query_engine.query(user_input)
        st.chat_message("assistant").markdown(response.response)
