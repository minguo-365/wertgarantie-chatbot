import streamlit as st
import os
from llama_index.core import (
    SimpleDirectoryReader,
    StorageContext,
    load_index_from_storage,
    VectorStoreIndex,
)
from llama_index.llms.openai import OpenAI
from llama_index.core.service_context import ServiceContext

# ã€é…ç½® API Key ã€‘
openai.api_key = os.getenv("OPENAI_API_KEY")

# ã€æ•°æ®è¯»å–å’Œç´¢å¼•ã€‘
docs = SimpleDirectoryReader("data").load_data()
llm = OpenAI(model="gpt-3.5-turbo")
service_context = ServiceContext.from_defaults(llm=llm)
index = VectorStoreIndex.from_documents(docs, service_context=service_context)

# ã€è®¾ç½® Streamlit UI ã€‘
st.set_page_config(page_title="Wertgarantie Chatbot", layout="wide")

st.markdown("""
    <h1 style='text-align: center;'>ğŸ§‘â€ğŸ’» Wertgarantie æ™ºèƒ½å®¢æœåŠ©æ‰‹</h1>
    <p style='text-align: center;'>
        åŸ¹è®­è‡ª Wertgarantie ç½‘ç«™çš„å†…å®¹ï¼Œæ”¯æŒä¸­æ–‡å’Œå¾·è¯­å¯¹è¯ ğŸ‡©ğŸ‡ª ğŸ‡¹ğŸ‡¼
    </p>
""", unsafe_allow_html=True)

# ã€è¾“å…¥çª—å£ã€‘
user_input = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š")

# ã€å¤„ç†å›å¤ã€‘
if user_input:
    query_engine = index.as_query_engine()
    response = query_engine.query(user_input)
    st.markdown(f"**ç­”å¤ï¼š** {response.response}")
